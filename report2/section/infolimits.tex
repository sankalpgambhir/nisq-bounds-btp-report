% infolimits.tex

Having proposed a structure to solve learning problems with a NISQ system, we
are ill-fated to then deal with the myriad of issues that arise with daring to
use it. Barring issues specific to the quantum states, low coherence times,
inaccurate measurements, et cetera, our structure itself
imposes some bottlenecks on what we can achieve with it. In particular, the act
of converting and transferring data between the representations used by the
quantum and classical halves induces the issue of information transfer and
limits upon it. 

The idea of information theoretic bounds goes back to the father of information
theory, Claude Shannon himself \cite{shannon1948mathematical}. Work from
Nyquist, Hartley, and Shannon \cite{hartley1928transmission} built up the
structure of information theory to quantify the maximum `amount of data' that
could be transferred through a noisy communications channel and the changes to
said effective `amount' on the implementation of error correcting codes over the
channel.

The analysis for the hybrid computing case has partially been performed in a
general setting \cite{lloyd2014information}. The authors suggest in the paper an
extension to construction of unitaries, but do not explore it further. To the
best of our knowledge, this has not been discussed in other literature since.
Here, we continue the discussion for the specific case of VQAs with the goal to
parametrize the discussion with circuit characteristics (depth, width, DLA) and
discuss the bounds on VQA computation from the optimal control theorems
presented in the paper.

\subsection{Summary of Bounds on Quantum Optimal Control}
\label{subsec:qoc}
A quantum system (target of control) can be presented as a dynamical equation

\begin{equation}
    \dot{\rho} = \mathcal{L}(\rho, \controlpulse(t))~,
\end{equation}

where \(\rho\) is the density matrix representing the current state of the
system, \(\dot{\rho}\) its time evolution, \(\controlpulse\) the externally
applied control pulse, and \(\mathcal{L}\), here, the resulting Liouvillian
superoperator \cite[see][section IV]{manzano2020lindblad}. The same notation is
used for the loss function earlier, and is kept here only to be consistent with
the source. The two will not be used together in this thesis.

The dynamics are subject to the boundary condition \(\rho(t=0) = \rho_0\), and
the unitary part of \(\mathcal{L}\) must be generated by a Hamiltonian

\begin{equation}
    \hamiltonian = \hamiltonian_D + \controlpulse(t) \hamiltonian_C~,
\end{equation}

where \(\hamiltonian_D\) and \(\hamiltonian_C\) are the drift and control
Hamiltonians respectively. The dynamics can be generalized to have several
control Hamiltonians and corresponding pulses, but the extension is
straightforward and skipped here for simplicity.

Now, for choices of the control pulse \(\controlpulse\), define the set of
reachable states as the set \(\reachable\), a manifold with dimension
\(\dimD_\reachable\), which is a subset of the space of density matrices of
dimension \(\dimD_\rho\), with of course \(\dimD_\reachable \leq \dimD_\rho\).
Thus, given a goal state \(\bar{\rho}\), and an initial state \(\rho_0\) the
problem is to find a (not necessarily unique) optimal control pulse
\(\bar{\controlpulse}\) such that it drives the initial state to a final state
within an \(\epsilon\)-ball around the goal state. This can be written as a
functional minimization

\begin{equation}
    \bar{\rho}(t) = \text{arg min}_{\controlpulse(t)} 
    \mathcal{F}(\rho_0, \bar{\rho}, \controlpulse(t), [\lambda_i])~,
\end{equation}

where the functional \(\mathcal{F}\) quantifying the distance between states may
also include constraints introduced via the Lagrangian multipliers
\(\{\lambda_i\}\).

To the end of this optimization, suppose one adjusts the control pulse with a
classical channel. In the ideal noiseless case, Hartley's Law bounds the
information transfer as

\begin{equation}
    b_\gamma = T\Delta\Omega\kappa_s~,
\end{equation}

where \(T\) is the pulse duration, \(\Delta\Omega\) the bandwidth, and
\(\kappa_s\) is the bit depth of the pulse. With the control pulse \(\gamma\)'s
extreme levels as \(\gamma_{max}\) and \(\gamma_{min}\), define \(\Delta\gamma =
\gamma_{max} - \gamma_{min}\). Finally, set the minimum variation to be
\(\delta\gamma\). Then,

\begin{equation}
    \kappa_s = \text{log}(1+\frac{\Delta\gamma}{\delta\gamma})~.
\end{equation}

These parameters can be used to give an error bound on the achievable state
\(\norm{\rho - \bar{\rho}} > \epsilon\), with

\begin{equation}
    \epsilon \geq 2^{-\frac{T\Delta\Omega\kappa_s}{\dimD_\polyreachable}}~.
    \label{eq:entropyerror}
\end{equation}

For a detailed build up to the results, see \cite{lloyd2014information}.

\subsection{Bounds on PQC Optimization}

Similar to the Optimal Control scenario, the VQA architecture also presents the
same infrastructural bounds. It stands to reason that a similar result should
extend to generation of unitaries using a PQC. This is suggested in
\cite[Supplemental Material]{lloyd2014information}, but not explored further. We
seek to establish lower bounds on the information theoretic error on learning
the unitaries in terms of the circuit parameters --- circuit width, depth, and
choice of generators (ansatz).

% Dw+ scaling
Following the discussion in \autoref{subsec:qoc},
\autoref{subsec:quantlandscape}, and \cite{larocca2021theory} about QFIMs and
entropy for a given number of parameters, we attempt to reconcile these two
theories. 

In general, \(\dimD_\polyreachable \sim \) maximum achievable rank of QFIM,
since both represent the over dimensionality of the reachable solution space.
While \cite{larocca2021theory,holmes2021connecting} suggest the existence of a
2-design may allow for this maximum achievable rank to scale linearly or
polynomially with the number of qubits \(n\), problems currently solvable within
the 2-design framework remain to be found. For most ansatzes used in practice,
to attain a usable level of expressiveness, the dimension of the problem is
exponential in the number of qubits accessible. This is well within expectations
due to the exponential scaling of the size of a Hilbert space in general.

\begin{equation}
    T\Delta\Omega\kappa_s \geq \dimD_\polyreachable \cdot \text{log}_2(\frac{1}{\epsilon}) \sim 2^n \text{log}_2(\frac{1}{\epsilon})
\end{equation}

This, in turn, following \autoref{eq:entropyerror}, establishes a bound on the
minimum precision attainable with a given bandwidth, or conversely the bandwidth
and/or time required to attain a given level of precision. It is clear to see
this required bandwidth scales with \(\dimD_\polyreachable\), and as such,
scales, in general, exponentially with the number of qubits utilized.

The established bandwidth constraints have several consequences on the design of
practical NISQ systems implementing VQAs, constraining the minimum size and
capability of hardware required to solve certain problems. It affects most the
general purpose hardware-efficient ansatzes which have been used due to their
ability to solve a large set of problems, hence being expressive, whilst being
easier to implement in practice. This is akin to using a universal gate to
implement circuits of choice. However, with these results in mind, it may be
more tractable to build problem-specific ansatzes, which may require hardware
reconfiguration to solve different problems, but may be the only path forward to
combat the exponential scaling of the Hilbert space and thus the bandwidth
requirements.

Extending this result to usable bounds for the outputs requires further study of
the maps discussed in \autoref{subsec:quantlandscape}. A preliminary result over
the state space is discussed in \autoref{app:qsvm}.
