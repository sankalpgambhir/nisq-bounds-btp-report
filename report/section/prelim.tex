% prelim.tex

% classical prelims
\subsection{Classical Computing}
% learning
\subsubsection{Learning Problem}
Learning \cite{cristianini2000introduction} can be broadly defined as attempting
to learn the input-output pattern given sample data. For this thesis, we
consider three major categories of learning problems:

\begin{itemize}
    \item Binary Classification --- input points in a chosen domain, and a
    binary output label for each point.
    \item Multi-Label Classification --- input points in a chosen domain, and
    one of \(n\) labels as output for each point.
    \item Regression --- input points in a chosen domain with real-valued
    output.
\end{itemize}

% classification problem
\subsubsection{Classification Problem}
We take as input elements \(\{x_i\}\), generally called \emph{feature vectors},
in a chosen domain \(\featurespace\) called the \emph{feature space} and output
an element from a finite set \(\labelset = {l_i}\) of labels.

The problem is called binary classification if \(\absolutevalue{\labelset} =
2\).

Formally, we attempt to learn a function \(f: \featurespace \to \labelset\)
given a set of inputs in the domain, and possibly paired output labels.

The problem proceeds in two manners given the form of inputs: if provided
input-output pairs, the problem is called a \emph{supervised learning problem},
while attempting to learn a set of labels given just (clustered) inputs is
called \emph{unsupervised} learning. We focus on supervised classification here.

The set of input-output pairs provided is called the \emph{training data}.

Given the difficulty of working with discretized domains, the input domain is
generally converted to be a subset of a Euclidean space, using a suitable
\emph{embedding function}.

% embedding
\subsubsection{Embedding}
An embedding of \(X\) in \(Y\) is a function \(f:X \to Y\) that is injective and
such that \(\text{image}(X) \subseteq Y\) has the same structure as \(X\). The
exact restrictions on the map to be structure-preserving depend on the
structures of the domain and the co-domain \cite{sankappanavar1981course}. It is
denoted here as \(f:X\hookrightarrow Y\).

For example, a topological embedding, i.e., the embedding of a topological
space, will be restricted to preserve its associated structure of open sets. A
field embedding, similarly, will be restricted to preserve the field operations
\(+\) and \(\times\).

For a given arbitrary feature space \(\featurespace\), it is generally embedded
into \(\reals^n\) for some \(n\).

% linear classification
\subsubsection{Linear Classification}
Classification generally proceeds by producing linear functions as candidate
labelling functions (supplemented with a discretization function) and fitting
them to the training data. For simplicity, we first restrict the discussion to
binary classifiers.

\begin{figure*}[ht]
    \centering
    \begin{subfigure}{0.48\textwidth}
        % unsep bs
        \centering
        \begin{tikzpicture}[>=stealth']
            % Draw axes
            \draw [<->,thick] (0,5) node (yaxis) [above] {}
                  |- (5,0) node (xaxis) [right] {};
            % draw negative dots
            \fill[black] (0.5,1.5)    circle (3pt);
            \fill[black] (2.0,2.7)   circle (3pt);
            \fill[black] (1.0,3.4)   circle (3pt);
            \fill[black] (3.0,2.0)   circle (3pt);
            \fill[black] (1.5,1.0)   circle (3pt);
            \fill[black] (2.5,0.5)   circle (3pt);
            % draw positive dots
            \draw[black] (3.5,1.5)     circle (3pt);
            \draw[black] (2.5,1.7)     circle (3pt);
            \draw[black] (1.5,2.3)     circle (3pt);
            \draw[black] (0.5,3.0)     circle (3pt);
          \end{tikzpicture}
          \caption{Unseparated data}
    \end{subfigure}
    \begin{subfigure}{0.48\textwidth}
        % nice and separated
        \centering
        \begin{tikzpicture}[>=stealth']
            % Draw axes
            \draw [<->,thick] (0,5) node (yaxis) [above] {}
                  |- (5,0) node (xaxis) [right] {};
            % separator
            \draw (-0.5, 4.0) -- (4.0,0.0) [dashed];
            % draw negative dots
            \fill[black] (0.5,1.5)    circle (3pt);
            \fill[black] (1.5,1.7)    circle (3pt);
            \fill[black] (2.0,0.5)    circle (3pt);
            \fill[black] (1.0,2.3)    circle (3pt);
            \fill[black] (2.5,0.6)    circle (3pt);
            % draw positive dots
            \draw[black] (3.5,1.5)     circle (3pt);
            \draw[black] (2.5,2.0)     circle (3pt);
            \draw[black] (1.5,3.5)     circle (3pt);
            \draw[black] (1.0,4.0)     circle (3pt);
            \draw[black] (0.5,3.8)     circle (3pt);
          \end{tikzpicture}
          \caption{Strongly separated data}
    \end{subfigure}
    \caption{The magic of the (strong) separation axiom.}
\end{figure*}

Given a set of points which, due to an embedding, may be assumed to be in
\(\featurespace\subseteq\reals^n\), attempting to classify them may still be an
arduous task if the spatial regions corresponding to the labels are intertwined.
Thus, to make the problem tractable, we restrict the data to be \emph{strongly}
separated, i.e., assume that there always exists a set of hyperplanes (of size
\(|L| - 1\)) that isolates the points with each label within the domains created
by intersection. In the binary case, this is just one label on either side of
the hyperplane.

% probability distribution separation? TODO
% inner product space? TODO

% svm
\subsubsection{Support Vector Machine}
A support vector machine is a classifier model which constructs a hyperplane or
a set of hyperplanes in the feature space optimizing classifier separation
depending on the objective \cite{cortes1995support}.

We will synonymously use the terms `Support Vector Machine' and that of its
common model `Maximal Margin Classifier', which is more appropriately what we
use here.

As the name suggests, a maximal margin classifier SVM tries not only to
construct a set of hyperplanes, but to find the set such that their margin from
the data is maximized. This builds upon the intuitive idea of a good separator
being further away from the given data points. See \autoref{fig:maxmargin}.


\begin{figure*}[ht]
    \centering
    \begin{subfigure}{0.48\textwidth}
        % unsep bs
        \centering
        \begin{tikzpicture}[>=stealth']
            % Draw axes
            \draw [<->,thick] (0,5) node (yaxis) [above] {}
                  |- (5,0) node (xaxis) [right] {};
            % classifier
            \draw[red, thick] (0.0, 4.0) -- (4.0, 0.0);
            \draw[->, thin] (1.0, 1.0) -- (2.0, 2.0);
            \draw[->, thick] (4.0, 4.0) -- node[near end, right] {\scriptsize Dominating Margin} (2.0, 2.0);
            \draw (3.0, 5.0) -- (5.0, 3.0) [dashed];
            \draw (0.0, 2.0) -- (2.0, 0.0) [dashed];
            % draw negative dots
            \fill[black] (1,1)    circle (3pt);
            % draw positive dots
            \draw[black] (4,4)     circle (3pt);
          \end{tikzpicture}
          \caption{Unoptimized margins}
    \end{subfigure}
    \begin{subfigure}{0.48\textwidth}
        % nice and separated
        \centering
        \begin{tikzpicture}[>=stealth']
            % Draw axes
            \draw [<->,thick] (0,5) node (yaxis) [above] {}
                  |- (5,0) node (xaxis) [right] {};
            % classifier
            \draw[red, thick] (0.5, 4.5) -- (4.5, 0.5);
            \draw[->] (1.0, 1.0) -- (2.5, 2.5);
            \draw[->] (4.0, 4.0) -- node[near end, right] {\scriptsize Equal Margins} (2.5, 2.5);
            \draw (3.0, 5.0) -- (5.0, 3.0) [dashed];
            \draw (0.0, 2.0) -- (2.0, 0.0) [dashed];
            % draw negative dots
            \fill[black] (1,1)    circle (3pt);
            % draw positive dots
            \draw[black] (4,4)     circle (3pt);
          \end{tikzpicture}
          \caption{Maximal margin classifier}
    \end{subfigure}
    \caption{Illustration of different margins for hyperplanes.}
    \label{fig:maxmargin}
\end{figure*}

Formally, we characterize a hyperplane in \(\reals^n\) as a pair \((\vecw, b)\),
with \(\vecw \in \reals^n\) and \(b \in \reals\), such that for all points
\(\vecx\) on the hyperplane

\begin{gather*}
    \innerprod{\vecw}{\vecx} + b = 0~.
\end{gather*}

Geometrically, \(\vecw\) is the vector normal to the hyperplane, and \(b\)
is the bias or offset from origin.

Note that by moving to \(\reals^{n+1}\), we can convert the hyperplane to one
without bias (passing through the origin)

\begin{gather*}
    \innerprod{\vecw}{\vecx} + b = 0~,\\
    \innerprod{(\vecw \oplus [b])}{(\vecx \oplus [1])} + 0 = 0~.
\end{gather*}

which is the hyperplane \((\vecw \oplus [b], 0)\) in \(\reals^{n+1}\), and
\([b]\) is the one element vector containing \(b\). So, without loss of
generality, we work with hyperplanes without bias.

Now, given the training dataset \({(\vec{x_i}, y_i)}\), with \(y_i = \pm 1\), we
can write constraints on \(\vecw\) as

\begin{gather}
    \forall i\; y_i \cdot \innerprod{\vecw}{\vec{x_i}} > 0~,
\end{gather}

that is, \(x_i\) is on the same side of the hyperplane as indicated by \(y_i\)
as the sign of the inner product corresponds to the same. 

By scaling \(\vecw\) (without changing the hyperplane), we can construct the
constraint system

\begin{gather}
    \forall i\; y_i \cdot \innerprod{\vecw}{\vec{x_i}} \geq 1~.
\end{gather}

Since we are scaling \(\vecw\), we choose an appropriate optimization target,
its norm.

Since this is a constrained optimization, we write its Lagrangian

\begin{gather}
    \mathcal{L}(\vecw, \vec{\alpha}) = \frac{1}{2} \innerprod{\vecw}{\vecw} + \sum_i \alpha_i \left[y_i \cdot \innerprod{\vecw}{\vec{x_i}}\right]~,
\end{gather}

where \(\{\alpha_i\}\) are the Lagrangian multipliers. For the optimal solution,
the Lagrangian is stationary, i.e.,

\begin{gather}
    \frac{\partial \mathcal{L}(\vecw, \vec{\alpha})}{\partial \vecw} = 0~,\nonumber\\
    \vecw + \sum_i \alpha_i y_i \vec{x_i} = 0~.
\end{gather}

Substituting this expression for \(\vecw\) in the Lagrangian itself, we get a
Lagrangian dependent solely on the parameters \(\{\alpha_i\}\) which we can
optimize over. By minimizing this Lagrangian, we obtain an optimal \(\vecw\)
which is the maximum margin classifier.

With \(\vecw\) fixed at its optimal value, we get a simple computational method
to classify all new incoming points \(\vecx \in \reals^n\), given by

\begin{gather}
    \text{sgn}(\innerprod{\vecw}{\vecx})
    \label{eq:svmclassifier}
\end{gather}

returning a label \(\pm 1\) (or anomalously zero, if you happen to pick a point
on the hyperplane, which can be remedied by making one side's boundary soft, by
changing \(>\) to \(\geq\)).

As the major `quantum' modification, we will discuss how the constrained linear
algebra computation is offloaded to a quantum circuit in \autoref{sec:vqa}.

% how optimise
\subsubsection{Optimisation Techniques}
The discussion of optimization techniques in classical computing is a long and
arduous one. We refer the reader to a common text on the matter for a detailed
discussion \cite{boyd2004convex,nocedal2006numerical}, while reviewing the
general ideas briefly here.

% actual discussion of common techniques
The goal of an optimization problem, given (generally) a function
\(\loss:X\to\reals\) is to find the minimum value in its range, and sometimes an
inverse in the domain, i.e., output a point \(x_* \in X\), such that

\begin{gather*}
    x_* = \text{arg min } \loss(x)~,
\end{gather*}

or the argument to \(\loss\) which minimizes it. In some problems, a local
minima may suffice, and in others, a global minimum may be the requirement.
Depending on the nature of the domain \(X\), different techniques may be
employed to find \(x_*\). These include gradient descent and its reductions
(finite element methods, etc.), Hessian-aided descent,  stochastic gradient
descent, among others. The rest of the discussion is agnostic of the
optimization routine, beyond, of course, the existence of one.

In a NISQ system, there is generally little to no attempt at error correction,
and the general goal is to capitalize on what is possible with the short
available coherence times, without devoting a majority of the system's resources
to error checking and correction. As such, these systems are unable to support
high-depth circuits with computationally involved analytical gradient based
approaches. An effective optimizer in control of such a temporally-bound circuit
should try to utilize techniques minimizing the number of measurements or
function evaluations, as the relevant modules generally form the bottleneck of
the computation \cite[see][chapter II.D]{bharti2021noisy}.

% qm prelims
\subsection{Quantum Regime}

% hilbert space
\subsubsection{Hilbert Space}
\begin{definition}
    A Hilbert space is a vector space \(\hilbertspace\) equipped with an inner
    product \(\innerproductabstract{f}{g} \;\forall f, g \in \hilbertspace\) such that
    the norm defined by

    \begin{equation*}
        \norm{f} = \sqrt{\innerproductabstract{f}{f}}
    \end{equation*}

    turns \(\hilbertspace\) into a complete metric space
    \cite{sansone1959orthogonal}.
\end{definition}

Physical quantities --- such as energy, momentum, and position --- are
represented as operators over a Hilbert space \(\hilbertspace\) to which the
wavefunctions belong \cite{hall2013quantum}. 
For our purposes, we will assume \(\hilbertspace\) to always
have as its base field the field of complex numbers, \(\complex\).

Herein, the complex inner product is assumed to be linear in the second factor,
i.e.,

\begin{equation*}
    \innerproductabstract{f}{\lambda g} = \lambda \innerproductabstract{f}{g}; \quad \innerproductabstract{\lambda f}{g} = \conjugate{\lambda} \innerproductabstract{f}{g}
\end{equation*}

\(\forall f, g \in \hilbertspace\) and \(\lambda \in \complex\). 

For every bounded operator \(A\) acting on a Hilbert Space, there is a unique
bounded operator \(A^*\) called its \emph{adjoint} such that

\begin{equation*}
    \innerproductabstract{f}{Ag} = \innerproductabstract{A^*f}{g}~.
\end{equation*}

We will assume relevant quantities to be linear operators \(\cdot :
\hilbertspace \to \hilbertspace\) with adjoints where necessary,
\cite[see][Appendix A]{hall2013quantum} for details.

% schrodinger
% \subsubsection{Schr\"odinger Equation}
% Given a \emph{Hamiltonian} operator \(\hamiltonian\) for a system represented by
% a wavefunction \(\psi\), its time evolution is given by the Schr\"odinger
% equation,

% \begin{equation}
%     \frac{\partial{\psi}}{\partial{t}} = \frac{1}{\iota\hbar} \hamiltonian \psi~.
%     \label{eq:schrodinger}
% \end{equation}

% quantum computer
\subsubsection{Quantum Computation}
In a quantum system, `computation' in its essence is jugglery of probability
amplitudes of states using unitary actions. After action of unitaries as
necessary, the coefficients are estimated using a measurement schema and
post-processed to recover the computational result. See
\cite{nielsen2002quantum} for a detailed study.

% quantum embedding
\subsubsection{State Construction and Embedding}
To perform computation in the quantum regime, data first needs to be converted
to a format in which it can be acted upon by quantum operators. This is again an
embedding function, specifically from the input domain to the Hilbert space of
quantum states for the system ansatz. See \cite{lloyd2020quantum} for details.

% distance measures
\subsubsection{Information Matrices and Distance Measures}
\label{subsubsec:distanceinfo}

Consider a parametrized distance function on quantum states 

\begin{equation}
    d(\parameters, \parameters') = d(\rho(\parameters), \rho(\parameters'))~.
\end{equation}

For close enough \(\parameters\) and \(\parameters'\) we can write a Taylor
expansion of the distance function. Clearly, the zeroth and first terms vanish,
as the distance of a state from itself is zero, and it forms a minimum for the
distance function. We have then the second order term

\begin{equation}
    d(\rho(\parameters), \rho(\parameters+\perturbdel)) = \frac{1}{2} \perturbdel^\top F(\parameters)\perturbdel~,
\end{equation}

with \(F\) representing the metric tensor

\begin{equation}
    F(\parameters) = \frac{\partial^2}{\partial\delta_i\partial\delta_j} d(\parameters, \parameters + \perturbdel) \bigg\vert_{\perturbdel = 0}~.
\end{equation}

Therefore, \(F\) captures all the information necessary to define a distance
metric. \(F\) is called the Quantum Fisher Information Matrix
\cite{meyer2021fisher}, and it is defined as

\begin{equation}
    \left[F_{ij}\right] = 4\text{Re} \left[\braket*{\partial_i\psi(\parameters)}{\partial_j\psi(\parameters)} - \braket*{\partial_i\psi(\parameters)}{\psi(\parameters)}\braket*{\psi(\parameters)}{\partial_j\psi(\parameters)}\right]~.
\end{equation}